{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74600d4c",
   "metadata": {},
   "source": [
    "# Edge AI Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c9984",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d243fa",
   "metadata": {},
   "source": [
    "## Model building and training\n",
    "\n",
    "### Overview\n",
    "\n",
    "We will now use the data collected in the previous section to train an artificial neural network-based Anomaly Detector of our design. To this end we will use an Autoencoder model. To understand why we choose such model we need to understand how it works. From [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder):\n",
    "\n",
    "> An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). The encoding is validated and refined by attempting to regenerate the input from the encoding. The autoencoder learns a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore insignificant data (“noise”).\n",
    "\n",
    "> Another application for autoencoders is **anomaly detection**. By learning to replicate the most salient features in the training data [...] the model is encouraged to learn to precisely reproduce the most frequently observed characteristics. When facing anomalies, the model should worsen its reconstruction performance. In most cases, only data with normal instances are used to train the autoencoder; in others, the frequency of anomalies is small compared to the observation set so that its contribution to the learned representation could be ignored. **After training, the autoencoder will accurately reconstruct \"normal\" data, while failing to do so with unfamiliar anomalous data**. Reconstruction error (the error between the original data and its low dimensional reconstruction) is used as an anomaly score to detect anomalies\n",
    "\n",
    "In simple terms: \n",
    "- The Autoencoder is a artificial neural network model that learns how to reconstruct the input data at the output. \n",
    "- If trained on \"normal\" data, it learns to recontruct **only normal data** and fails to reconstruct anomalies.\n",
    "- We can detect anomalies by computing the reconstruction error of the Autoencoder. If the error is above a certain threshold (which we will decide) the input sample is an anomaly.\n",
    "\n",
    "Why did we choose this approach over others?\n",
    "- The Autoencoder falls in the \"[Unsupervised Learning](https://en.wikipedia.org/wiki/Unsupervised_learning)\" category: it doesn't need labeled data to be trained i.e. we don't need to go through all the dataset and manually label the samples as \"normal\" or \"anomaly\" ([Supervised Learning](https://en.wikipedia.org/wiki/Supervised_learning)).\n",
    "- Simpler data collection: we just need to provide it with the \"normal\" data. We don't need to artificially generate anomalies to train it on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a09146",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "We can now work on our `train-data-raw.csv`. The dataset is provided within this repository.\n",
    "\n",
    "If you're running this notebook through Google Colab you'll need to download the dataset running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e652ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e401f",
   "metadata": {},
   "source": [
    "Let's start taking a look at the content of this dataset, we'll use [pandas](https://pandas.pydata.org/) (Python Data Analysis library) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95543e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv(\"./train-data-raw.csv\")\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab22fae",
   "metadata": {},
   "source": [
    "#### Feature selection\n",
    "\n",
    "As you might notice there's some information in the dataset we don't care about and are not meaningful for our application:\n",
    "- `ID`\n",
    "- The various `timestamps`\n",
    "- `assetName` which doesn't change\n",
    "\n",
    "Then we can remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba782ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['ACC_Y', 'ACC_X', 'ACC_Z',\n",
    "            'PRESSURE', 'TEMP_PRESS', 'TEMP_HUM',\n",
    "            'HUMIDITY', 'GYRO_X', 'GYRO_Y', 'GYRO_Z']\n",
    "\n",
    "data = raw_data[features]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41bb7e-d505-40a4-9852-b61f04faadfc",
   "metadata": {},
   "source": [
    "**Note**: Some of you might notice that this is a really simple dataset: some of the input data (like `GYRO_*` and `ACC_*`) do not change much over time. Such a dataset is not very challenging and a few, well-placed, thresholds might be sufficient to spot anomalous behaviour. For this tutorial we decided to keep things simple and easy to replicate. Anomalies can be simply triggered by moving the Raspberry Pi around.\n",
    "\n",
    "Keep in mind that this approach is generic: any dataset from any appliance/connected device can be processed in the same way we're showing here. That's the magic of neural networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893251c",
   "metadata": {},
   "source": [
    "#### Feature scaling\n",
    "\n",
    "AI models don't perform well when the input numerical attributes have very different scales. As you can see `ACC_X`, `ACC_Y` and `ACC_Z` range from 0 to 1, while the `PRESSURE` have far higher values.\n",
    "\n",
    "There are two common ways to address this: _normalization_ and _standardization_.\n",
    "\n",
    "_Normalization_ (a.k.a. Min-max scaling) shifts and rescales values so that they end up ranging from 0 to 1. This can be done by subtracting the min value and dividing by the max minus the min.\n",
    "\n",
    "x' = $\\frac{x - min(x)}{max(x) - min(x)}$\n",
    "\n",
    "_Standardization_ makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation.\n",
    "\n",
    "x' = $\\frac{x - avg(x)}{\\sigma}$\n",
    "\n",
    "Fortunately for us [scikit-learn](https://scikit-learn.org/stable/) library provides a function for both of them. In this case we'll use _normalization_ because it works well for this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed7d19-2bc9-4b7f-a241-695d205efeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data used in the Triton preprocessor\")\n",
    "print(\"-----------Min-----------\")\n",
    "print(data.min())\n",
    "print(\"-----------Max-----------\")\n",
    "print(data.max())\n",
    "print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scaled_data).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c527f1",
   "metadata": {},
   "source": [
    "#### Train test split\n",
    "\n",
    "The only way to know how well a model will generalize to new data points is to try it on new data. To do so we split our data into two sets: the training set and the test set.\n",
    "\n",
    "To do so we'll use a function from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_train, x_test = train_test_split(scaled_data, test_size=0.3, random_state=42)\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f45b25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d817ad",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "We can now leverage the [Keras](https://keras.io/) API of [Tensorflow](https://www.tensorflow.org/) for creating our Autoencoder and then train it on our dataset.\n",
    "\n",
    "We'll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed knowledge representation of the original input (also called the _latent-space representation_). If the input features were each independent of one another, this compression and subsequent reconstruction would be a very difficult task. However, if some sort of structure exists in the data (ie. correlations between input features), this structure can be learned and consequently leveraged when forcing the input through the network's bottleneck.\n",
    "\n",
    "The bottleneck consists of reducing the number of neurons for each layer of the neural network up to a certain point, and then increase the number until the original input number is reached. This will result in a hourglass shape which is typical for the Autoencoders.\n",
    "\n",
    "![image16.png](imgs/img16.png)\n",
    "\n",
    "#### Build the Autoencoder model\n",
    "\n",
    "In this example we'll use a basic fully-connected autoencoder but keep in mind that autoencoders can be built with different classes of neural network (i.e. Convolutional Neural Networks, Recurrent Neural Networks etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2966fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2' # Avoid AVX2 error\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "def create_model(input_dim):\n",
    "    # The encoder will consist of a number of dense layers that decrease in size\n",
    "    # as we taper down towards the bottleneck of the network, the latent space\n",
    "    input_data = Input(shape=(input_dim,), name='INPUT0')\n",
    "\n",
    "    # hidden layers\n",
    "    encoder = Dense(9, activation='tanh', name='encoder_1')(input_data)\n",
    "    encoder = Dropout(.15)(encoder)\n",
    "    encoder = Dense(6, activation='tanh', name='encoder_2')(encoder)\n",
    "    encoder = Dropout(.15)(encoder)\n",
    "\n",
    "    # bottleneck layer\n",
    "    latent_encoding = Dense(3, activation='linear', name='latent_encoding')(encoder)\n",
    "\n",
    "    # The decoder network is a mirror image of the encoder network\n",
    "    decoder = Dense(6, activation='tanh', name='decoder_1')(latent_encoding)\n",
    "    decoder = Dropout(.15)(decoder)\n",
    "    decoder = Dense(9, activation='tanh', name='decoder_2')(decoder)\n",
    "    decoder = Dropout(.15)(decoder)\n",
    "\n",
    "    # The output is the same dimension as the input data we are reconstructing\n",
    "    reconstructed_data = Dense(input_dim, activation='linear', name='OUTPUT0')(decoder)\n",
    "\n",
    "    autoencoder_model = Model(input_data, reconstructed_data)\n",
    "\n",
    "    return autoencoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a63862",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model = create_model(len(features))\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6357e8-8bab-4fba-a8fc-4e861c7a11eb",
   "metadata": {},
   "source": [
    "![image17.png](imgs/img17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9105a68",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "\n",
    "As we already explained, the autoencoder is a  type of artificial neural network used to learn efficient codings of unlabeled data. We'll use that to reconstruct the input at the output. To train an autoencoder we don’t need to do anything fancy, just throw the raw input data at it. Autoencoders are considered an unsupervised learning technique since they don’t need explicit labels to train on but to be more precise they are self-supervised because they generate their own labels from the training data.\n",
    "\n",
    "To train our neural network we need to have a performance metric to measure how well it is learning to reconstruct the data i.e. our _loss function_. The loss function in our example, which we need to minimize during our training, is the error between the _input data_ and the _data reconstructed by the autoencoder_. We'll use the [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error).\n",
    "\n",
    "MSE = $\\frac{1}{n}\\sum_{i=1}^{n}{(Y_i - Y'_i)^2}$\n",
    "\n",
    "Where:\n",
    "- $n$: is the number of features (10 in our example)\n",
    "- $Y_i$: is the original data point i.e. the input of the autoencoder \n",
    "- $Y'_i$: is the reconstructed data point i.e. the output of the autoencoder\n",
    "\n",
    "Before starting the training we need to set the [**hyperparameters**](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)). Hyperparameters are parameters whose values control the learning process and determine the values of model parameters that a learning algorithm ends up learning. These are the `learning_rate`, `max_epochs`, `optimizer` and the `batch_size` you see in the code snippet below. You may ask yourself how to set them, it all comes down to trial and error. Try tweaking them below and see how they affect the learning process...\n",
    "\n",
    "A good explaination of their meaning can be found in the [Keras documentation](https://keras.io/api/models/model_training_apis/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "batch_size = 32\n",
    "max_epochs = 15\n",
    "learning_rate = .0001\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "autoencoder_model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "train_history = autoencoder_model.fit(x_train, x_train,\n",
    "                      shuffle=True,\n",
    "                      epochs=max_epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af6d4d-c65c-4e4e-a811-28ff05f94b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.legend(['loss on train data', 'loss on test data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd73b5c0-dd8c-4238-8d24-cdf9df30b12e",
   "metadata": {},
   "source": [
    "Here we can see the loss for the training set and the test set on the epochs.\n",
    "\n",
    "Some of you might notice that this graph is somewhat unexpected. Why the validation loss is lower than the train loss? This is the effect of the regularization: regularization terms and dropout layer are affecting the network during training. A good writeup of this effect can be found [here](https://towardsdatascience.com/what-your-validation-loss-is-lower-than-your-training-loss-this-is-why-5e92e0b1747e).\n",
    "\n",
    "As an excercise try and compute the average MSE on the training set and the test set. You'll find that the MSE is lower in the training set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a8528",
   "metadata": {},
   "source": [
    "We can now save the model on disk as we'll use this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83811ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.save(\"./saved_model/autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./saved_model/autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7d005",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad6601",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We now have a model that reconstruct the input at the output... doesn't sounds really useful right?\n",
    "\n",
    "Let's see it in action. Let's take a sample from the test set and run it through our autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = x_test[3:4].copy() # Deep copy\n",
    "\n",
    "reconstructed_sample = autoencoder_model.predict(input_sample)\n",
    "\n",
    "print(input_sample)\n",
    "print(reconstructed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.arange(10)\n",
    "bar_width = 0.35\n",
    "\n",
    "figure, ax = plt.subplots()\n",
    "\n",
    "inbar = ax.bar(index, input_sample[0], bar_width, label=\"Input data\")\n",
    "recbar = ax.bar(index+bar_width, reconstructed_sample[0], bar_width, label=\"Reconstruced data\")\n",
    "\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(features, rotation = 45)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bc7dd",
   "metadata": {},
   "source": [
    "As we can see from the graph above it reconstructed the input fairly well. It is not perfect since the Autoencoder is lossy but it is good enough\n",
    "\n",
    "What happens if we manipulate this sample in a way the autoencoder doesn't expect (i.e. we introduce an **anomaly**)?\n",
    "\n",
    "Let's try and set the `ACC_Z` to a value the autoencoder has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_anomaly = input_sample.copy() # Deep copy\n",
    "\n",
    "input_anomaly[0][2] = 0.15\n",
    "\n",
    "reconstructed_anomaly = autoencoder_model.predict(input_anomaly)\n",
    "\n",
    "print(input_anomaly)\n",
    "print(reconstructed_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77393430",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "\n",
    "inbar = ax.bar(index, input_anomaly[0], bar_width, label=\"Input anomaly\")\n",
    "recbar = ax.bar(index+bar_width, reconstructed_anomaly[0], bar_width, label=\"Reconstruced anomaly\")\n",
    "\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(features, rotation = 45)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06166d2a",
   "metadata": {},
   "source": [
    "The autoencoder fails to reconstruct the data it received at the input. This means that the reconstruction error is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd374df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"Anomaly %f\"% mean_squared_error(input_anomaly[0], reconstructed_anomaly[0]))\n",
    "print(\"Normal  %f\"% mean_squared_error(input_sample[0], reconstructed_sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3391f",
   "metadata": {},
   "source": [
    "**It's working as expected!**\n",
    "\n",
    "We now need to decide when to trigger an alarm (i.e. classify an input sample as anomalous) from this reconstruction error. In other words we need to decide our threshold.\n",
    "\n",
    "There are multiple ways to set this value, in this example we'll use the [Z-Score](https://en.wikipedia.org/wiki/Standard_score).\n",
    "\n",
    "From Wikipedia:\n",
    "> In statistics, the standard score is the number of standard deviations by which the value of a raw score (i.e., an observed value or data point) is above or below the mean value of what is being observed or measured.[...]\n",
    ">\n",
    "> It is calculated by subtracting the population mean from an individual raw score and then dividing the difference by the population standard deviation.\n",
    "\n",
    "We'll consider a sample an anomaly if the Reconstruction Error Z-Score is not in the range \\[-2, +2\\]. This means that if the reconstruction error for a sample is more than 2 standard deviation away from the average reconstruction error computed on the test set, the sample is an anomaly. This choice is arbirtary, we can control the sensitivity of the detector by changing this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_recon = autoencoder_model.predict(x_test)\n",
    "reconstruction_scores = np.mean((x_test - x_test_recon)**2, axis=1)  # MSE\n",
    "\n",
    "reconstruction_scores_pd = pd.DataFrame({'recon_score': reconstruction_scores})\n",
    "print(reconstruction_scores_pd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37738a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(mse_sample):\n",
    "    return (mse_sample - reconstruction_scores_pd.mean())/reconstruction_scores_pd.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bb404-ad11-4438-8832-55e087cc7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_anomaly = mean_squared_error(input_anomaly[0], reconstructed_anomaly[0])\n",
    "mse_normal = mean_squared_error(input_sample[0], reconstructed_sample[0])\n",
    "\n",
    "z_score_anomaly = z_score(mse_anomaly)\n",
    "z_score_normal = z_score(mse_normal)\n",
    "\n",
    "print(\"Anomaly Z-score %f\"% z_score_anomaly)\n",
    "print(\"Normal Z-score %f\"% z_score_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb17c8",
   "metadata": {},
   "source": [
    "We now have our anomaly detector... let's see how we can deploy it on our Kura&trade;-powered edge device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e27579",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460cd4a4",
   "metadata": {},
   "source": [
    "## Model deployment\n",
    "\n",
    "To deploy our model on the target device we'll leverage Kura&trade;'s newly added [Nvidia&trade; Triton Inferece Server](https://developer.nvidia.com/nvidia-triton-inference-server) integration.\n",
    "\n",
    "![image18.png](imgs/img18.png)\n",
    "\n",
    "The Nvidia™ Triton Inference Server is an open-source inference service software that enables the user to deploy trained AI models from any framework on GPU or CPU infrastructure. It supports all major frameworks like TensorFlow, TensorRT, PyTorch, ONNX Runtime, and even custom framework backend. With specific backends, it is also possible to run Python scripts, mainly for pre-and post-processing purposes, and exploit the DALI building block for optimized operations.\n",
    "\n",
    "The Nvidia™ Triton Inference Server container should already be running on your system.\n",
    "\n",
    "We'll also need to use Kura&trade;'s Triton bundles:\n",
    "- [Triton Server Component](https://marketplace.eclipse.org/content/triton-server-component-eclipse-kura-5): for Kura-Triton integration\n",
    "- [AI Wire Component](https://marketplace.eclipse.org/content/ai-wire-component-eclipse-kura-5): for making the Triton Inference Server available through the Kura Wires as a Wire component.\n",
    "\n",
    "These bundles have been already installed on your Eclipse Kura&trade;\n",
    "\n",
    "### Model conversion\n",
    "\n",
    "The first step in using Triton to serve your models is to place one or more models into a [model repository](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_repository.md) i.e. a folder were the model are available for Triton to load. Depending on the type of the model and on what Triton capabilities you want to enable for the model, you may need to create a [model configuration](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md) for the model. This configuration is a protobuf containing informations about runtime configuration and input/output shape accepted by the model.\n",
    "\n",
    "For our autoencoder model we'll need three \"models\":\n",
    "- A **Preprocessor** for performing the operations described in the [\"Data processing\"](#Data-Processing) section (Wire envelop translation, feature selection and scaling)\n",
    "- The **Autoencoder** model we exported in the [\"Model training\"](#Model-training) section\n",
    "- A **Postprocessor** for performing the operations described in the [\"Model evaluation\"](#Model-evaluation) section (Reconstruction error computation)\n",
    "\n",
    "To simplify the handling of these models and improve inference performance, we'll use an advanced feature of Triton wich is an [Ensemble Model](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/architecture.md#ensemble-models). From Triton official documentation:\n",
    "\n",
    "> An ensemble model represents a pipeline of one or more models and the connection of input and output tensors between those models. Ensemble models are intended to be used to encapsulate a procedure that involves multiple models, such as \"data preprocessing -> inference -> data postprocessing\". Using ensemble models for this purpose can avoid the overhead of transferring intermediate tensors and minimize the number of requests that must be sent to Triton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b5de3-0dcf-44b3-a1e6-58ee551e216d",
   "metadata": {},
   "source": [
    "#### Autoencoder\n",
    "\n",
    "As seen in the [\"Model training\"](#Model-training) section, our model is available as a [Tensorflow _SavedModel_](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_repository.md#tensorflow-models) which can be simply loaded by the Triton [Tensorflow backend](https://github.com/triton-inference-server/tensorflow_backend). We just need to configure it properly.\n",
    "\n",
    "We'll start by creating the following folder structure\n",
    "\n",
    "```\n",
    "tf_autoencoder_fp32\n",
    "├── 1\n",
    "│   └── model.savedmodel\n",
    "│       ├── assets\n",
    "│       ├── keras_metadata.pb\n",
    "│       ├── saved_model.pb\n",
    "│       └── variables\n",
    "│           ├── variables.data-00000-of-00001\n",
    "│           └── variables.index\n",
    "└── config.pbtxt\n",
    "```\n",
    "\n",
    "This can be done by copying the model we saved in the Model Training section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56fa55-6332-447d-bbbe-4d76ab46202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./tf_autoencoder_fp32/ && mkdir -p ./tf_autoencoder_fp32/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eeeb5e-2959-4df6-b7ed-32b8d305fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc13c4-40b3-4fb4-b0ae-c5df800d06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r ./saved_model/autoencoder tf_autoencoder_fp32/1/model.savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdebc28-0337-4a52-bdd6-0a900a13de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find tf_autoencoder_fp32 -maxdepth 3 -ls # or !tree tf_autoencoder_fp32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e03e71-9e68-4ef0-a692-e1724180f67a",
   "metadata": {},
   "source": [
    "Now comes the hard part: we need to provide the [model configuration](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md) (i.e. the `config.pbtxt` file). In the case of the autoencoder is pretty simple:\n",
    "\n",
    "```protobuf\n",
    "name: \"tf_autoencoder_fp32\"\n",
    "backend: \"tensorflow\"\n",
    "max_batch_size: 0\n",
    "input [\n",
    "    {\n",
    "    name: \"INPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1, 10 ]\n",
    "    }\n",
    "]\n",
    "output [\n",
    "    {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1, 10 ]\n",
    "    }\n",
    "]\n",
    "version_policy: { all { }}\n",
    "instance_group [{ kind: KIND_CPU }]\n",
    "```\n",
    "\n",
    "Each model `input` and `output` must specify the `name`, `data_type` and `dims`. We already know all of these:\n",
    "- `name`: corresponds to the layer name we've seen in the Model Training section. `INPUT0` for the input and `OUTPUT0` for the output.\n",
    "- `data_type`: will be float since we didn't perform any quantization\n",
    "- `dims`: is the shape of the in/out tensor. In this case it will correspond to an array with the same length as the number of features.\n",
    "\n",
    "Other interesting parameters of this configuration are:\n",
    "- `backend`: where we set the backend for the model. In this case it will be the Tensorflow backend\n",
    "- `name`: the name of the model that must correspond to the name of the folder\n",
    "- `instance_group`: where we set where we want the model to run. In this case we'll use the CPU since we're on a Raspberry Pi but keep in mind that Triton support multiple accelerators.\n",
    "\n",
    "for a deep dive into the model configuration parameter take a look at the [official documentation](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_configuration.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546893f3-02c3-46f1-822a-2af4bd2cdd40",
   "metadata": {},
   "source": [
    "#### Preprocessor\n",
    "\n",
    "As discussed in the [\"Data processing\"](#Data-Processing) section, before providing the incoming data to the autoencoder, we need to perform feature selection and scaling. In addition to these responsibilites, the Preprocessor will need to perform a sort of serialization of the data to comply to the input shape accepted by the Autoencoder. This is due to how Kura manages the data running on Wires. More details can be found [here](https://eclipse.github.io/kura/docs-develop/kura-wires/single-port-wire-components/ai-wire-component/#models-input-and-output-formats).\n",
    "\n",
    "To perform all of this we'll use the [Python backend](https://github.com/triton-inference-server/python_backend) available in Triton.\n",
    "\n",
    "As described in the previous section we will need to provide the following folder structure:\n",
    "\n",
    "```\n",
    "preprocessor\n",
    "├── 1\n",
    "│   └── model.py\n",
    "└── config.pbtxt\n",
    "```\n",
    "\n",
    "##### Preprocessor Configuration\n",
    "\n",
    "As discussed in the [official Kura documentation](https://eclipse.github.io/kura/docs-develop/kura-wires/single-port-wire-components/ai-wire-component/#models-input-and-output-formats):\n",
    "\n",
    "> The AI wire component takes a WireEnvelope as an input, it processes its records and feeds them to the specified preprocessing or inference model.\n",
    ">\n",
    "> ...\n",
    ">\n",
    "> The models that manage the input and the output must expect a list of inputs such that:\n",
    "> - each input corresponds to an entry of the `WireRecord` properties\n",
    "> - the entry key will become the input name (e.g. in the case of an asset, the channel name becomes the tensor name)\n",
    "> - input shape will be `[1]`\n",
    "\n",
    "Therefore for our `input` we'll have that each name corresponds to the names we've seen in the Data Collection section. The `output` needs to correspond to the input accepted by the model (i.e. `INPUT0`).\n",
    "\n",
    "```protobuf\n",
    "name: \"preprocessor\"\n",
    "backend: \"python\"\n",
    "\n",
    "input [\n",
    "  {\n",
    "    name: \"ACC_X\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "input [\n",
    "  {\n",
    "    name: \"ACC_Y\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    " ...\n",
    "input [\n",
    "  {\n",
    "    name: \"TEMP_PRESS\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"INPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1, 10 ]\n",
    "  }\n",
    "]\n",
    "instance_group [{ kind: KIND_CPU }]\n",
    "```\n",
    "\n",
    "##### Preprocessor Model\n",
    "\n",
    "As we've seen in the Data Processing section the Preprocessor is responsible for scaling the input features and serializing them in the tensor shape expected by the Autoencoder model.\n",
    "\n",
    "This can be done with the following python script:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import triton_python_backend_utils as pb_utils\n",
    "\n",
    "\n",
    "class TritonPythonModel:\n",
    "\n",
    "    def initialize(self, args):\n",
    "        self.model_config = model_config = json.loads(args['model_config'])\n",
    "\n",
    "        output0_config = pb_utils.get_output_config_by_name(\n",
    "            model_config, \"INPUT0\")\n",
    "\n",
    "        self.output0_dtype = pb_utils.triton_string_to_numpy(\n",
    "            output0_config['data_type'])\n",
    "\n",
    "    def execute(self, requests):\n",
    "        output0_dtype = self.output0_dtype\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        for request in requests:\n",
    "            acc_x      = pb_utils.get_input_tensor_by_name(request, \"ACC_X\").as_numpy()\n",
    "            acc_y      = pb_utils.get_input_tensor_by_name(request, \"ACC_Y\").as_numpy()\n",
    "            acc_z      = pb_utils.get_input_tensor_by_name(request, \"ACC_Z\").as_numpy()\n",
    "            gyro_x     = pb_utils.get_input_tensor_by_name(request, \"GYRO_X\").as_numpy()\n",
    "            gyro_y     = pb_utils.get_input_tensor_by_name(request, \"GYRO_Y\").as_numpy()\n",
    "            gyro_z     = pb_utils.get_input_tensor_by_name(request, \"GYRO_Z\").as_numpy()\n",
    "            humidity   = pb_utils.get_input_tensor_by_name(request, \"HUMIDITY\").as_numpy()\n",
    "            pressure   = pb_utils.get_input_tensor_by_name(request, \"PRESSURE\").as_numpy()\n",
    "            temp_hum   = pb_utils.get_input_tensor_by_name(request, \"TEMP_HUM\").as_numpy()\n",
    "            temp_press = pb_utils.get_input_tensor_by_name(request, \"TEMP_PRESS\").as_numpy()\n",
    "\n",
    "            out_0 = np.array([acc_y, acc_x, acc_z, pressure, temp_press, temp_hum, humidity, gyro_x, gyro_y, gyro_z]).transpose()\n",
    "\n",
    "            #                  ACC_Y     ACC_X     ACC_Z    PRESSURE   TEMP_PRESS   TEMP_HUM   HUMIDITY    GYRO_X    GYRO_Y    GYRO_Z\n",
    "            min = np.array([-0.132551, -0.049693, 0.759847, 976.001709, 38.724998, 40.220890, 13.003981, -1.937896, -0.265019, -0.250647])\n",
    "            max = np.array([ 0.093099, 0.150289, 1.177543, 1007.996338, 46.093750, 48.355824, 23.506138, 1.923712, 0.219204, 0.671759])\n",
    "\n",
    "            # MinMax scaling\n",
    "            out_0_scaled = (out_0 - min)/(max - min)\n",
    "\n",
    "            # Create output tensor\n",
    "            out_tensor_0 = pb_utils.Tensor(\"INPUT0\",\n",
    "                                           out_0_scaled.astype(output0_dtype))\n",
    "\n",
    "            inference_response = pb_utils.InferenceResponse(\n",
    "                output_tensors=[out_tensor_0])\n",
    "            responses.append(inference_response)\n",
    "\n",
    "        return responses\n",
    "```\n",
    "\n",
    "Here there are two important things to note:\n",
    "- The template we're using is taken from the Triton documentation and can be found [here](https://github.com/triton-inference-server/python_backend/blob/main/examples/add_sub/model.py).\n",
    "- The MinMax scaling **must be the same we used in our training**. For illustration purposes we wrote the `min` and `max` arrays we found in the Data Processing section but we could have serialized the `MinMaxScaler` using [`pickle`](https://docs.python.org/3/library/pickle.html) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa10670-93d7-4f7d-98c3-8a3de21c38fa",
   "metadata": {},
   "source": [
    "#### Postprocessor\n",
    "\n",
    "As discussed in the [\"Data processing\"](#Data-Processing) section, to perform the anomaly detection step we need to compute the Mean Squared Error between the recontructed data and the actual input data. Due to this the configuration of the Postprocessor model will be somewhat more complicated than before: in addition to the output of the Autoencoder model we will need the output of the Preprocessor model.\n",
    "\n",
    "To perform all of this we'll use the [Python backend](https://github.com/triton-inference-server/python_backend) again.\n",
    "\n",
    "As described in the previous section we will need to provide the following folder structure:\n",
    "\n",
    "```\n",
    "postprocessor\n",
    "├── 1\n",
    "│   └── model.py\n",
    "└── config.pbtxt\n",
    "```\n",
    "\n",
    "##### Postprocessor Configuration\n",
    "\n",
    "```protobuf\n",
    "name: \"postprocessor\"\n",
    "backend: \"python\"\n",
    "\n",
    "input [\n",
    "  {\n",
    "    name: \"RECONSTR0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1, 10 ]\n",
    "  }\n",
    "]\n",
    "input [\n",
    "  {\n",
    "    name: \"ORIG0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1, 10 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"ANOMALY_SCORE0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"ANOMALY0\"\n",
    "    data_type: TYPE_BOOL\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "instance_group [{ kind: KIND_CPU }]\n",
    "```\n",
    "\n",
    "As we can see we have two inputs and two outputs:\n",
    "- The first input tensor is the reconstruction performed by the autoencoder model\n",
    "- The second input tensor is the original data (already scaled and serialized by the Preprocessor model)\n",
    "- The first output is the anomaly score i.e. the reconstruction error between the original and the reconstructed data.\n",
    "- The second output is a boolean representing whether the data constitute an anomaly or not\n",
    "\n",
    "Let's see how this is computed by the Python model.\n",
    "\n",
    "##### Postprocessor Model\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import triton_python_backend_utils as pb_utils\n",
    "\n",
    "def z_score(mse):\n",
    "    return (mse - MEAN_MSE)/STD_MSE\n",
    "\n",
    "\n",
    "class TritonPythonModel:\n",
    "\n",
    "    def initialize(self, args):\n",
    "        self.model_config = model_config = json.loads(args['model_config'])\n",
    "\n",
    "        output0_config = pb_utils.get_output_config_by_name(\n",
    "            model_config, \"ANOMALY_SCORE0\")\n",
    "        output1_config = pb_utils.get_output_config_by_name(\n",
    "            model_config, \"ANOMALY0\")\n",
    "\n",
    "        self.output0_dtype = pb_utils.triton_string_to_numpy(\n",
    "            output0_config['data_type'])\n",
    "        self.output1_dtype = pb_utils.triton_string_to_numpy(\n",
    "            output1_config['data_type'])\n",
    "\n",
    "    def execute(self, requests):\n",
    "        output0_dtype = self.output0_dtype\n",
    "        output1_dtype = self.output1_dtype\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        for request in requests:\n",
    "            # Get input\n",
    "            x_recon = pb_utils.get_input_tensor_by_name(request, \"RECONSTR0\").as_numpy()\n",
    "            x_orig = pb_utils.get_input_tensor_by_name(request, \"ORIG0\").as_numpy()\n",
    "\n",
    "            # Get Mean square error between reconstructed input and original input\n",
    "            reconstruction_score = np.mean((x_orig - x_recon)**2, axis=1)\n",
    "            \n",
    "            # Z-Score of Mean square error must be inside [-2; 2]\n",
    "            anomaly = np.array([z_score(reconstruction_score) < -2.0 or z_score(reconstruction_score) > 2.0])\n",
    "\n",
    "            # Create output tensors\n",
    "            out_tensor_0 = pb_utils.Tensor(\"ANOMALY_SCORE0\",\n",
    "                                           reconstruction_score.astype(output0_dtype))\n",
    "            out_tensor_1 = pb_utils.Tensor(\"ANOMALY0\",\n",
    "                                           anomaly.astype(output1_dtype))\n",
    "\n",
    "            inference_response = pb_utils.InferenceResponse(\n",
    "                output_tensors=[out_tensor_0, out_tensor_1])\n",
    "            responses.append(inference_response)\n",
    "\n",
    "        return responses\n",
    "```\n",
    "\n",
    "As you can see the script is simple:\n",
    "- It gets the input tensors\n",
    "- It computes the Mean Squared Error between the inputs (which is what we called the reconstruction error)\n",
    "- It computes the Z-Score of the MSE computed for the current sample and flags it as an anomaly if it is farther than 2 standard deviations away from the average MSE.\n",
    "\n",
    "**Note**: `MEAN_MSE` and `STD_MSE` are the mean value and the standard deviation of the Mean Squared Error computed on the test set and correspond to the `reconstruction_scores_pd.mean()` and `reconstruction_scores_pd.std()` we used in the previous section. We didn't set them as they change for every training performed on the Autoencoder. Be sure to set it to their proper values before trying this model on the Triton server!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715b658-49d8-42ba-b93e-14580cb0d598",
   "metadata": {},
   "source": [
    "### Ensemble model\n",
    "\n",
    "To make things easier for ourselves and improve performance we'll consolidate the AI pipeline into an [Ensemble Model](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/architecture.md#ensemble-models).\n",
    "\n",
    "We will need to provide the following folder structure:\n",
    "\n",
    "```\n",
    "ensemble_pipeline\n",
    "├── 1\n",
    "└── config.pbtxt\n",
    "```\n",
    "\n",
    "Note that the `1` folder is **empty**. The ensemble model essentially describe *how to connect the models that belong to the processing pipeline*.\n",
    "\n",
    "Therefore we'll need to focus on the configuration only.\n",
    "\n",
    "```protobuf\n",
    "name: \"ensemble_pipeline\"\n",
    "platform: \"ensemble\"\n",
    "max_batch_size: 0\n",
    "input [\n",
    "  {\n",
    "    name: \"ACC_X\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "input [\n",
    "  {\n",
    "    name: \"ACC_Y\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    " ...\n",
    "input [\n",
    "  {\n",
    "    name: \"TEMP_PRESS\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"ANOMALY_SCORE0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"ANOMALY0\"\n",
    "    data_type: TYPE_BOOL\n",
    "    dims: [ 1 ]\n",
    "  }\n",
    "]\n",
    "ensemble_scheduling {\n",
    "  step [\n",
    "    {\n",
    "      model_name: \"preprocessor\"\n",
    "      model_version: -1\n",
    "      input_map{\n",
    "          key: \"ACC_X\"\n",
    "          value: \"ACC_X\"\n",
    "      }\n",
    "      input_map{\n",
    "          key: \"ACC_Y\"\n",
    "          value: \"ACC_Y\"\n",
    "      }\n",
    "       ...\n",
    "      input_map{\n",
    "          key: \"TEMP_PRESS\"\n",
    "          value: \"TEMP_PRESS\"\n",
    "      }\n",
    "      output_map {\n",
    "        key: \"INPUT0\"\n",
    "        value: \"preprocess_out\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      model_name: \"tf_autoencoder_fp32\"\n",
    "      model_version: -1\n",
    "      input_map {\n",
    "        key: \"INPUT0\"\n",
    "        value: \"preprocess_out\"\n",
    "      }\n",
    "      output_map {\n",
    "        key: \"OUTPUT0\"\n",
    "        value: \"autoencoder_output\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      model_name: \"postprocessor\"\n",
    "      model_version: -1\n",
    "      input_map {\n",
    "        key: \"RECONSTR0\"\n",
    "        value: \"autoencoder_output\"\n",
    "      }\n",
    "      input_map {\n",
    "        key: \"ORIG0\"\n",
    "        value: \"preprocess_out\"\n",
    "      }\n",
    "      output_map {\n",
    "        key: \"ANOMALY_SCORE0\"\n",
    "        value: \"ANOMALY_SCORE0\"\n",
    "      }\n",
    "      output_map {\n",
    "        key: \"ANOMALY0\"\n",
    "        value: \"ANOMALY0\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "The configuration is split in two main parts:\n",
    "- The first is the usual configuration we've seen before: we describe what are the input and the output of our model. In this case the input will correspond to the input of the first model of the pipeline (the Preprocessor) and the output to the output of the last model of the pipeline (the Postprocessor)\n",
    "- The second part describe how to map the input/output of the models within the pipeline\n",
    "\n",
    "To better visualize the configuration we can look at the graph below.\n",
    "\n",
    "![image19.png](imgs/img19.png)\n",
    "\n",
    "#### Conversion results\n",
    "\n",
    "At this point we should have a folder structure that looks like this:\n",
    "\n",
    "```\n",
    "models\n",
    "├── ensemble_pipeline\n",
    "│   ├── 1\n",
    "│   └── config.pbtxt\n",
    "├── postprocessor\n",
    "│   ├── 1\n",
    "│   │   └── model.py\n",
    "│   └── config.pbtxt\n",
    "├── preprocessor\n",
    "│   ├── 1\n",
    "│   │   └── model.py\n",
    "│   └── config.pbtxt\n",
    "└── tf_autoencoder_fp32\n",
    "    ├── 1\n",
    "    │   └── model.savedmodel\n",
    "    │       ├── assets\n",
    "    │       ├── keras_metadata.pb\n",
    "    │       ├── saved_model.pb\n",
    "    │       └── variables\n",
    "    │           ├── variables.data-00000-of-00001\n",
    "    │           └── variables.index\n",
    "    └── config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbe9ca",
   "metadata": {},
   "source": [
    "Now let's go back to our tutorial file !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
